{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8217984-1372-4344-adb4-b9062d6faad1",
   "metadata": {},
   "source": [
    "# MobilityPySpark UDTs\n",
    "\n",
    "This notebook serves as a basic example to how MobilityPySpark handles UDTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57922580-3771-47ad-b42b-f0dd4f6de03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymeos import *\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pysparkmeos.UDT.MeosDatatype import *\n",
    "from pysparkmeos.utils.udt_appender import udt_append\n",
    "from pysparkmeos.utils.utils import *\n",
    "from pysparkmeos.UDF.udf import *\n",
    "\n",
    "from typing import *\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46116603-94ea-4055-bdd0-95da47f48a80",
   "metadata": {},
   "source": [
    "## Initialize PySpark and PyMEOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd79c533-ab3d-4b7d-bfcb-79f1a50d0191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/23 09:16:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/07/23 09:17:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/07/23 09:17:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/07/23 09:17:11 WARN SimpleFunctionRegistry: The function length replaced a previously registered function.\n",
      "24/07/23 09:17:11 WARN SimpleFunctionRegistry: The function nearest_approach_distance replaced a previously registered function.\n"
     ]
    }
   ],
   "source": [
    "# Initialize PyMEOS\n",
    "pymeos_initialize(\"UTC\")\n",
    "\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS']= \"notebook\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark UDT Example with PyMEOS\") \\\n",
    "    .master(\"local[3]\") \\\n",
    "    .config(\"spark.default.parallelism\", 3) \\\n",
    "    .config(\"spark.executor.memory\", \"3g\") \\\n",
    "    .config(\"spark.executor.cores\", 1) \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", 0) \\\n",
    "    .config(\"spark.sql.allowMultipleTableArguments.enabled\", True) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#spark.sparkContext.setLogLevel(\"DEBUG\")\n",
    "\n",
    "# Append the UDT mapping to the PyMEOS classes\n",
    "udt_append()\n",
    "\n",
    "# Register the UDFs in spark\n",
    "register_udfs_under_spark_sql(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948d5e58-47ee-473a-b267-19b155a0e049",
   "metadata": {},
   "source": [
    "We have an example dataset prepared, let's explore it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f55a6882-bc52-4c79-9aea-86f1a2bf40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../datasets/preproc.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "974b4895-3430-4a4d-a52f-28ffaf877570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icao24,pointStr\n",
      "34718e,POINT(1.9229736328125 40.87294006347656)@2022-06-27 00:00:00+00\n"
     ]
    }
   ],
   "source": [
    "!head -n 2 $data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb659c-f5e1-4e16-b060-05a75765029d",
   "metadata": {},
   "source": [
    "## Read UDTs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cae530-e101-40ad-bebe-b3c0ca96f24e",
   "metadata": {},
   "source": [
    "Apparently we already have a preprocessed set of Points that can be easily read by MobilityPySpark, by defining a schema using TGeogPointInstUDT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9185fba-b2fd-4856-9bea-d9fb531c14a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- icao24: string (nullable = true)\n",
      " |-- PointStr: pythonuserdefined (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|icao24|           PointInst|               STBox|\n",
      "+------+--------------------+--------------------+\n",
      "|34718e|POINT(1.922973632...|SRID=4326;GEODSTB...|\n",
      "|ac6364|POINT(-85.5262662...|SRID=4326;GEODSTB...|\n",
      "|406471|POINT(1.838302612...|SRID=4326;GEODSTB...|\n",
      "|a04417|POINT(-83.4583702...|SRID=4326;GEODSTB...|\n",
      "|c04aa1|POINT(-79.3079393...|SRID=4326;GEODSTB...|\n",
      "+------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(icao24='34718e', PointStr=TGeogPointInstWrap(POINT(1.9229736328125 40.87294006347656)@2022-06-27 00:00:00+00))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"icao24\", StringType()),\n",
    "    StructField(\"PointStr\", TGeogPointInstUDT())  \n",
    "])\n",
    "df = spark.read.csv(\n",
    "    data_path, \n",
    "    header=True, \n",
    "    schema=schema,\n",
    "    mode='PERMISSIVE'\n",
    ")\n",
    "df.printSchema()\n",
    "df.withColumnRenamed(\"PointStr\", \"PointInst\").withColumn(\"STBox\", point_to_stbox(\"PointInst\")).show(5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96df7cd5-428d-4096-b46b-20e260885353",
   "metadata": {},
   "source": [
    "## Write UDTs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cc0da9-b6f1-498a-b89a-58e69e041f95",
   "metadata": {},
   "source": [
    "Now we save the dataframe back in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d423dca2-f254-4745-a186-7aa42fa8917d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.csv(\"../datasets/out.csv\")\n",
    "df.write.parquet(\"../datasets/out.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eeb6190-d96e-4d49-b660-e398072e870b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000-ca918e4c-36f8-40c7-90fa-e0c7924029f8-c000.csv  _SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!ls ../../out.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e599b45-bd60-4e0d-89d5-bb678bb66a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000-30bf6d15-c985-4def-b2dc-9fa66dad9502-c000.snappy.parquet  _SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!ls ../../out.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8769f2d4-27d2-4481-bd48-9a9063348682",
   "metadata": {},
   "source": [
    "This is a very simple notebook that shows how using UDTs allows for basic read/write operations in MobilityPySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5622ba17-d6cc-4b62-903f-16b4c134cf50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
