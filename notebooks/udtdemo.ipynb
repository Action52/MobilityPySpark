{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8217984-1372-4344-adb4-b9062d6faad1",
   "metadata": {},
   "source": [
    "# MobilityPySpark UDTs\n",
    "\n",
    "This notebook serves as a basic example to how MobilityPySpark handles UDTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57922580-3771-47ad-b42b-f0dd4f6de03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymeos import *\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pysparkmeos.UDT.MeosDatatype import *\n",
    "from pysparkmeos.utils.udt_appender import udt_append\n",
    "from pysparkmeos.utils.utils import *\n",
    "from pysparkmeos.UDF.udf import *\n",
    "from pysparkmeos.partitions.grid_partitioner import GridPartition\n",
    "from pysparkmeos.UDTF.base_partition_udtf import BasePartitionUDTF\n",
    "\n",
    "from typing import *\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46116603-94ea-4055-bdd0-95da47f48a80",
   "metadata": {},
   "source": [
    "## Initialize PySpark and PyMEOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd79c533-ab3d-4b7d-bfcb-79f1a50d0191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/23 13:49:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/07/23 13:49:18 WARN SimpleFunctionRegistry: The function length replaced a previously registered function.\n",
      "24/07/23 13:49:18 WARN SimpleFunctionRegistry: The function nearest_approach_distance replaced a previously registered function.\n"
     ]
    }
   ],
   "source": [
    "# Initialize PyMEOS\n",
    "pymeos_initialize(\"UTC\")\n",
    "\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS']= \"notebook\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark UDT Example with PyMEOS\") \\\n",
    "    .master(\"local[3]\") \\\n",
    "    .config(\"spark.default.parallelism\", 3) \\\n",
    "    .config(\"spark.executor.memory\", \"3g\") \\\n",
    "    .config(\"spark.executor.cores\", 1) \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", 0) \\\n",
    "    .config(\"spark.sql.allowMultipleTableArguments.enabled\", True) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#spark.sparkContext.setLogLevel(\"DEBUG\")\n",
    "\n",
    "# Append the UDT mapping to the PyMEOS classes\n",
    "udt_append()\n",
    "\n",
    "# Register the UDFs in spark\n",
    "register_udfs_under_spark_sql(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948d5e58-47ee-473a-b267-19b155a0e049",
   "metadata": {},
   "source": [
    "We have an example dataset prepared, let's explore it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f55a6882-bc52-4c79-9aea-86f1a2bf40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../datasets/preproc.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "974b4895-3430-4a4d-a52f-28ffaf877570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icao24,pointStr\n",
      "34718e,POINT(1.9229736328125 40.87294006347656)@2022-06-27 00:00:00+00\n"
     ]
    }
   ],
   "source": [
    "!head -n 2 $data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb659c-f5e1-4e16-b060-05a75765029d",
   "metadata": {},
   "source": [
    "## Read UDTs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cae530-e101-40ad-bebe-b3c0ca96f24e",
   "metadata": {},
   "source": [
    "Apparently we already have a preprocessed set of Points that can be easily read by MobilityPySpark, by defining a schema using TGeogPointInstUDT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9185fba-b2fd-4856-9bea-d9fb531c14a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- icao24: string (nullable = true)\n",
      " |-- PointStr: pythonuserdefined (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|icao24|           PointInst|               STBox|\n",
      "+------+--------------------+--------------------+\n",
      "|34718e|POINT(1.922973632...|STBOX XT(((1.9229...|\n",
      "|ac6364|POINT(-85.5262662...|STBOX XT(((-85.52...|\n",
      "|406471|POINT(1.838302612...|STBOX XT(((1.8383...|\n",
      "|a04417|POINT(-83.4583702...|STBOX XT(((-83.45...|\n",
      "|c04aa1|POINT(-79.3079393...|STBOX XT(((-79.30...|\n",
      "|4d21ea|POINT(8.005793644...|STBOX XT(((8.0057...|\n",
      "|4ca9cc|POINT(8.388679504...|STBOX XT(((8.3886...|\n",
      "|a20f1a|POINT(-77.7057878...|STBOX XT(((-77.70...|\n",
      "|152019|POINT(52.04384408...|STBOX XT(((52.043...|\n",
      "|a895b4|POINT(-80.0497055...|STBOX XT(((-80.04...|\n",
      "|845d1c|POINT(134.1781997...|STBOX XT(((134.17...|\n",
      "|aa84f8|POINT(-112.043282...|STBOX XT(((-112.0...|\n",
      "|a0a8df|POINT(-96.9305003...|STBOX XT(((-96.93...|\n",
      "|7c7a4d|POINT(153.0453608...|STBOX XT(((153.04...|\n",
      "|750503|POINT(101.9908194...|STBOX XT(((101.99...|\n",
      "|a721d5|POINT(-120.366270...|STBOX XT(((-120.3...|\n",
      "|a888aa|POINT(-96.4073364...|STBOX XT(((-96.40...|\n",
      "|a61d3e|POINT(-120.854129...|STBOX XT(((-120.8...|\n",
      "|a047db|POINT(-90.9573974...|STBOX XT(((-90.95...|\n",
      "|71bf19|POINT(126.7658042...|STBOX XT(((126.76...|\n",
      "+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(icao24='34718e', PointInst=TGeomPointInstWrap(POINT(1.9229736328125 40.87294006347656)@2022-06-27 00:00:00+00), STBox=STBoxWrap(STBOX XT(((1.9229736328125,40.87294006347656),(1.9229736328125,40.87294006347656)),[2022-06-27 00:00:00+00, 2022-06-27 00:00:00+00])))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"icao24\", StringType()),\n",
    "    StructField(\"PointStr\", TGeomPointInstUDT())  \n",
    "])\n",
    "df = spark.read.csv(\n",
    "    data_path, \n",
    "    header=True, \n",
    "    schema=schema,\n",
    "    mode='PERMISSIVE'\n",
    ")\n",
    "df.printSchema()\n",
    "df = df.withColumnRenamed(\"PointStr\", \"PointInst\").withColumn(\"STBox\", point_to_stbox(\"PointInst\"))\n",
    "df.show()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2c56f6-a583-49a6-821f-f922417a3f0d",
   "metadata": {},
   "source": [
    "### Parse as Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c58231da-5e37-46c2-88b8-237cec706797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/23 13:49:29 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|icao24|            PointSeq|\n",
      "+------+--------------------+\n",
      "|4bb186|[POINT(27.8621292...|\n",
      "|4074e2|[POINT(-75.162197...|\n",
      "|ac0d09|[POINT(-72.187853...|\n",
      "|c08106|[POINT(-79.407135...|\n",
      "|a1286c|[POINT(-69.845206...|\n",
      "|010207|[POINT(26.7178734...|\n",
      "|4d0113|[POINT(-100.32571...|\n",
      "|a046eb|[POINT(-95.526492...|\n",
      "|aa909a|[POINT(-75.856049...|\n",
      "|0d0d40|[POINT(-116.00980...|\n",
      "|ac6343|[POINT(-116.00452...|\n",
      "|ab128d|[POINT(-121.75960...|\n",
      "|4d21ea|[POINT(8.00579364...|\n",
      "|a86b76|[POINT(-118.19572...|\n",
      "|ac3b8e|[POINT(-86.820799...|\n",
      "|406471|[POINT(1.83830261...|\n",
      "|a393e6|[POINT(-101.17403...|\n",
      "|a18581|[POINT(-110.19602...|\n",
      "|50840d|[POINT(7.81187315...|\n",
      "|a64a3b|[POINT(-70.762065...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dfseq = df.dropna().groupBy(\"icao24\").agg(\n",
    "    F.collect_list(F.col(\"PointInst\")).alias(\"PointSeq\")\n",
    ")\n",
    "dfseq = dfseq.withColumn(\"PointSeq\", tgeompointseq_from_instant_list(\"PointSeq\"))\n",
    "dfseq.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a10aa7-f9e4-4e16-b0bb-05b9c8d8eb49",
   "metadata": {},
   "source": [
    "## Define a Simple Grid and Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "521fd27f-ebf1-45b5-b9a1-eeb362110454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "STBoxWrap(STBOX XT(((-121.75960459607712,-32.06538391113281),(153.0453608586238,53.242767333984375)),[2022-06-27 00:00:00+00, 2022-06-27 00:00:10+00]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = df.rdd.mapPartitions(lambda x: bounds_calculate_map(x, colname='PointInst')).reduce(bounds_calculate_reduce)\n",
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e302d27c-501d-432f-8330-1357295cdb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|tileid|                tile|\n",
      "+------+--------------------+\n",
      "|     0|STBOX XT(((-121.7...|\n",
      "|     1|STBOX XT(((-121.7...|\n",
      "|     2|STBOX XT(((-121.7...|\n",
      "|     3|STBOX XT(((-121.7...|\n",
      "|     4|STBOX XT(((15.642...|\n",
      "|     5|STBOX XT(((15.642...|\n",
      "|     6|STBOX XT(((15.642...|\n",
      "|     7|STBOX XT(((15.642...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid = GridPartition(bounds=bounds, cells_per_side=2)\n",
    "griddf = grid.as_spark_table()\n",
    "griddf.createOrReplaceTempView(\"grid\")\n",
    "griddf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cad079d-da68-4c5d-9f63-125712be9569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/23 14:00:53 WARN SimpleTableFunctionRegistry: The function demoudtf replaced a previously registered function.\n",
      "[Stage 28:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+--------------------+\n",
      "|movingobjectid|tileid|        movingobject|\n",
      "+--------------+------+--------------------+\n",
      "|             0|     7|{[POINT(27.862129...|\n",
      "|             1|     3|{[POINT(-75.16219...|\n",
      "|             2|     3|{[POINT(-72.18785...|\n",
      "|             3|     3|{[POINT(-79.40713...|\n",
      "|             4|     3|{[POINT(-69.84520...|\n",
      "|             5|     7|{[POINT(26.717873...|\n",
      "|             6|     3|{[POINT(-100.3257...|\n",
      "|             7|     3|{[POINT(-95.52649...|\n",
      "|             8|     1|{[POINT(-75.85604...|\n",
      "|             9|     3|{[POINT(-116.0098...|\n",
      "|            10|     3|{[POINT(-116.0045...|\n",
      "|            11|     3|{[POINT(-121.7596...|\n",
      "|            12|     2|{[POINT(8.0057936...|\n",
      "|            13|     3|{[POINT(-118.1957...|\n",
      "|            14|     3|{[POINT(-86.82079...|\n",
      "|            15|     2|{[POINT(1.8383026...|\n",
      "|            16|     3|{[POINT(-101.1740...|\n",
      "|            17|     3|{[POINT(-110.1960...|\n",
      "|            18|     3|{[POINT(7.8118731...|\n",
      "|            19|     3|{[POINT(-70.76206...|\n",
      "+--------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "partition_schema = StructType(\n",
    "    [\n",
    "        StructField(\"movingobjectid\", StringType()),\n",
    "        StructField(\"tileid\", IntegerType()),\n",
    "        StructField(\"movingobject\", TGeomPointSeqSetUDT()),\n",
    "    ]\n",
    ")\n",
    "@F.udtf(returnType=partition_schema)\n",
    "class DemoUDTF(BasePartitionUDTF):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            response_extra_cols=[],\n",
    "            check_function=None,\n",
    "            return_full_traj=False\n",
    "        )\n",
    "\n",
    "    def eval(self, row: Row):\n",
    "        for val in super().eval_wrap(row):\n",
    "            yield val\n",
    "\n",
    "query = \"\"\"\n",
    "            SELECT *\n",
    "            FROM DemoUDTF(\n",
    "                TABLE(\n",
    "                        SELECT\n",
    "                            monotonically_increasing_id() AS trajectory_id,\n",
    "                            PointSeq AS movingobject,\n",
    "                            (SELECT collect_list(tile) FROM grid) AS tiles,\n",
    "                            (SELECT collect_list(tileid) FROM grid) AS tileids\n",
    "                        FROM dfseq\n",
    "                )\n",
    "            )\n",
    "\"\"\"\n",
    "\n",
    "dfseq.createOrReplaceTempView(\"dfseq\")\n",
    "spark.udtf.register(\"DemoUDTF\", DemoUDTF)\n",
    "partitioned = spark.sql(query)\n",
    "partitioned.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96df7cd5-428d-4096-b46b-20e260885353",
   "metadata": {},
   "source": [
    "## Write UDTs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cc0da9-b6f1-498a-b89a-58e69e041f95",
   "metadata": {},
   "source": [
    "Now we save the dataframe back in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d423dca2-f254-4745-a186-7aa42fa8917d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "partitioned.write.partitionBy('tileid').csv(\"../datasets/out.csv\", mode=\"overwrite\", header=True)\n",
    "partitioned.write.partitionBy('tileid').parquet(\"../datasets/out.parquet\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4eeb6190-d96e-4d49-b660-e398072e870b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ../datasets/out.csv/_SUCCESS\n",
      "\n",
      "'../datasets/out.csv/tileid=1':\n",
      "part-00000-cd8e5db9-7546-4b93-8860-04c0cff51e9a.c000.csv\n",
      "\n",
      "'../datasets/out.csv/tileid=2':\n",
      "part-00000-cd8e5db9-7546-4b93-8860-04c0cff51e9a.c000.csv\n",
      "\n",
      "'../datasets/out.csv/tileid=3':\n",
      "part-00000-cd8e5db9-7546-4b93-8860-04c0cff51e9a.c000.csv\n",
      "\n",
      "'../datasets/out.csv/tileid=5':\n",
      "part-00000-cd8e5db9-7546-4b93-8860-04c0cff51e9a.c000.csv\n",
      "\n",
      "'../datasets/out.csv/tileid=7':\n",
      "part-00000-cd8e5db9-7546-4b93-8860-04c0cff51e9a.c000.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../datasets/out.csv/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e599b45-bd60-4e0d-89d5-bb678bb66a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " _SUCCESS  'tileid=1'  'tileid=2'  'tileid=3'  'tileid=5'  'tileid=7'\n"
     ]
    }
   ],
   "source": [
    "!ls ../datasets/out.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8769f2d4-27d2-4481-bd48-9a9063348682",
   "metadata": {},
   "source": [
    "This is a very simple notebook that shows how using UDTs allows for basic read/write operations in MobilityPySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5622ba17-d6cc-4b62-903f-16b4c134cf50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
